{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4a5a1bb",
   "metadata": {},
   "source": [
    "# Bank marketing\n",
    "\n",
    "**1. Project description**\n",
    "+ **1.1 Goal**\n",
    "+ **1.2 Data**\n",
    "+ **1.3 Data provider**\n",
    "+ **1.4 Software**\n",
    "\n",
    "**2. Exploratory Data Analysis** \n",
    "+ **2.1 Loading the dataset**\n",
    "+ **2.2 Missing values**\n",
    "+ **2.3 Data types**\n",
    "+ **2.4 Feature importance and analysis of target variable.**\n",
    "+ **2.5 Doing the train/validation/test split**\n",
    "+ **2.6 Encoding the categorical variables**\n",
    "+ **2.7 Scaling**\n",
    "\n",
    "**3. Model training** \n",
    "+ **3.1 Metric selection**\n",
    "+ **3.2 Logistic Regression**\n",
    "+ **3.3 Decision Tree**\n",
    "+ **3.4 Random Forest**\n",
    "+ **3.5 XGBoost**\n",
    "+ **3.6 Model selection**\n",
    "\n",
    "**4. Exporting the notebook to a python script**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a6fdf9",
   "metadata": {},
   "source": [
    "## 1. Project description\n",
    "\n",
    "### 1.1 Goal\n",
    "\n",
    "The classification goal is to predict if the bank client will subscribe (yes/no) a fix term deposit (target variable 'deposit') after a marketing campaign. It might help the bank in designing promotions, new campaigns, and understanding controversial campaign results.\n",
    "\n",
    "### 1.2 Data\n",
    "\n",
    "###### Bank client data:\n",
    "- age (numeric)\n",
    "- job : type of job (categorical: 'admin.','blue-collar','entrepreneur','housemaid','management','retired','self-employed','services','student','technician','unemployed','unknown')\n",
    "- marital : marital status (categorical: 'divorced','married','single','unknown'; note: 'divorced' means divorced or widowed)\n",
    "- education (categorical: 'primary', 'secondary', 'terciary','unknown')\n",
    "- default: has credit in default? (categorical: 'no','yes','unknown')\n",
    "- balance: not in the original data set, probably how much money the client has in the bank\n",
    "- housing: has housing loan? (categorical: 'no','yes','unknown')\n",
    "- loan: has personal loan? (categorical: 'no','yes','unknown')\n",
    "- contact: contact communication type (categorical: 'cellular','telephone','unknown)\n",
    "- month: last contact month of year (categorical: 'jan', 'feb', 'mar', ..., 'nov', 'dec')\n",
    "- day_of_week: last contact day of the week (categorical: 'mon','tue','wed','thu','fri')\n",
    "- duration: last contact duration, in seconds (numeric). Important note: this attribute highly affects the output target (e.g., if duration=0 then y='no'). Yet, the duration is not known before a call is performed. Also, after the end of the call y is obviously known. Thus, this input should only be included for benchmark purposes and should be discarded if the intention is to have a realistic predictive model.\n",
    "\n",
    "###### Campaign-related attributes:\n",
    "- campaign: number of contacts performed during this campaign and for this client (numeric, includes last contact)\n",
    "- pdays: number of days that passed by after the client was last contacted from a previous campaign (numeric; '-1' means client was not previously contacted)\n",
    "- previous: number of contacts performed before this campaign and for this client (numeric)\n",
    "- poutcome: outcome of the previous marketing campaign (categorical: 'failure','nonexistent','success')\n",
    "\n",
    "###### Output variable (desired target):\n",
    "- deposit - has the client subscribed a term deposit? (binary: 'yes','no')\n",
    "\n",
    "### 1.3 Data provider\n",
    "\n",
    "Original dataset: [UCI Machine learning repository](https://archive.ics.uci.edu/ml/datasets/Bank%2BMarketing)\n",
    "\n",
    "Here we use a subset of the dataset dowloaded from [Kaggle](https://www.kaggle.com/janiobachmann/bank-marketing-dataset). There are some minor differences:\n",
    "+ this Kaggle dataset is balanced (in the Discussion tab at the Kaggle webpage in the link it is said that the resampling was probably done by bootstrapping). \n",
    "+ the variable 'education' has been simplified in the Kaggle dataset to 'primary', 'secondary', 'terciary', and 'unknown', the original values were: 'basic.4y', 'basic.6y', 'basic.9y', 'high.school', 'illiterate', 'professional.course', 'university.degree', 'unknown'.\n",
    "+ in the Kaggle dataset the variable 'pdays' takes the value '-1' (instead of '999' as in the original dataset) when the client was not previously contacted.\n",
    "+ the Kaggle dataset has a column named 'balance' and does not have the 'Social and economic context attributes' (like euribor 3 moth rate) shown in the original dataset.\n",
    "\n",
    "Citation: _A Data-Driven Approach to Predict the Success of Bank Telemarketing._ S. Moro, P. Cortez and P. Rita. Decision Support Systems, Elsevier, 62:22-31, June 2014\n",
    "\n",
    "### 1.4 Software"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d736f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import mutual_info_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import export_text\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6a69d84",
   "metadata": {},
   "source": [
    "## 2. Exploratory Data Analysis    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b7aeb69",
   "metadata": {},
   "source": [
    "### 2.1 Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636e15ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/home/mmc/Desktop/DataTalks/mid_term_project/\"  \n",
    "df = pd.read_csv(path + \"bank.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "880d7f23",
   "metadata": {},
   "source": [
    "### 2.2 Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b357835e",
   "metadata": {},
   "outputs": [],
   "source": [
    "max(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cad9e8c",
   "metadata": {},
   "source": [
    "There are not missing values in the dataset but many values are 'unknown'. We checked that the model performance is fine by having 'unknown' as a value. The model decision power might be reduced (i.e., predictions involving variables with 'unknown' values might not be very informative, see the Decision Tree Classifier section), however we prefer to do not replace these values by NaN or zeros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba570e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df == 'unknown'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb9f1548",
   "metadata": {},
   "source": [
    "### 2.3 Data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc83070",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "935d1176",
   "metadata": {},
   "source": [
    "Some categorical variables can easily be converted to numeric for the EDA:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7fc088",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace with numbers 0 (negative or 'no') and 1 (positive or 'yes')\n",
    "df.default = (df.default == 'yes').astype(int)\n",
    "df.loan = (df.loan == 'yes').astype(int)\n",
    "df.housing = (df.housing == 'yes').astype(int)\n",
    "df.deposit = (df.deposit == 'yes').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b414bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical = df.select_dtypes(include=['object']).columns.tolist()\n",
    "numerical = df.select_dtypes(include=['int64']).columns.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c076b58",
   "metadata": {},
   "source": [
    "### 2.4 Feature importance\n",
    "\n",
    "To identify which features affect the target variable 'deposit'."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f38b56",
   "metadata": {},
   "source": [
    "##### Numerical variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a86b1a9",
   "metadata": {},
   "source": [
    "##### A. Range of values and basic stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b065287d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe().round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c249659a",
   "metadata": {},
   "source": [
    "Different columns show very different range of values, we will need to scale (see below, after the data split)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b5896f0",
   "metadata": {},
   "source": [
    "##### B. Pair plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef695334",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This visualization takes a while, set the if as \"True\" to run it\n",
    "if True:#False: \n",
    "    colors = [\"#f58e00\", \"g\"]\n",
    "    labels = \"No\", \"Yes\"\n",
    "    hue_order = [0, 1]\n",
    "\n",
    "    ax = sns.pairplot(df, hue='deposit', palette=colors, hue_order=hue_order)\n",
    "    ax.fig.suptitle('Pair Plots to show potential dependencies between numerical features (double-click to enlarge)',\n",
    "                family='Serif', size=30, ha='center', weight='bold', y = 1.01)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e7b371",
   "metadata": {},
   "source": [
    "The pair plots do not show obvious dependencies."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa618de",
   "metadata": {},
   "source": [
    "##### C. Frequency distribution\n",
    "\n",
    "The diagonal of the pair plots above show the frequency distribution of the numerical features. The target variable 'deposit' is quite balanced:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a859c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('seaborn-whitegrid')\n",
    "df.deposit.hist(bins=20, figsize=(2,4), color=\"#f58e00\")\n",
    "plt.suptitle('Distribution of the target variable', family = 'Serif', \n",
    "             size = 15,weight = 'bold')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a36b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.deposit.value_counts(normalize=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a8844af",
   "metadata": {},
   "source": [
    "##### D. Correlation by the [Pearson coefficient](https://en.wikipedia.org/wiki/Pearson_correlation_coefficient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d430035b",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_corr = df.corr().round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae42694",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(25,10))\n",
    "plt.rc('font', size=15) \n",
    "sns.heatmap(matrix_corr,annot=True,linewidths=.5, cmap=\"Greens\")\n",
    "plt.title('Heatmap showing correlations between numerical data')\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fd5387f",
   "metadata": {},
   "source": [
    "The feature 'duration', i.e., the duration of the last contact, shows the higher correlation with the target deposit. However, as mentioned in the data provider section above, it might be because if 'duration'=0 then 'deposit'='no', and the call duration is not known before a call is performed. Thus, this input should only be included for benchmark purposes and should be discarded if the intention is to have a realistic predictive model (see the section Model Selection of a comparison of the results including and not including this feature).\n",
    "\n",
    "Apart from 'duration', the next highest correlations in the numerical features are a positve correlation with 'pdays' (days from last contact) and 'previous' (contacts before this campaign) and negative correlations with 'housing', 'campaign' (contacts in this campaign) and 'loan' (people with loans might not engage to the fix term deposit)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e173e4e",
   "metadata": {},
   "source": [
    "##### E. ROC AUC for feature importance\n",
    "\n",
    "The [ROC AUC](https://en.wikipedia.org/wiki/Receiver_operating_characteristic) is the probability that a randomly selected positive example (someone that will agree to open a fix term deposit) has a higher score (higher probability to be predicted as positive or higher feature value if, like here, we want to use ROC AUC for feature important), than a randomly selected negative example (someone that will not open a fix term deposit)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c638c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_scores = []\n",
    "\n",
    "for col in numerical:       \n",
    "    auc = roc_auc_score(df.deposit, df[col]) \n",
    "    if auc < 0.5: # in case the feature is negatively correlated with the target\n",
    "        auc = roc_auc_score(df.deposit, -df[col]) \n",
    "    feature_scores.append((col, auc))\n",
    "\n",
    "columns = ['feature', 'ROC_AUC']\n",
    "df_scores = pd.DataFrame(feature_scores, columns=columns)\n",
    "df_scores.sort_values(by=['ROC_AUC'],ascending=False).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1298602e",
   "metadata": {},
   "source": [
    "Again, apart from 'duration', that can be problematic, as the data provider mentioned above, the highest ROC AUC in the numerical features are 'housing', 'previous' (contacts before this campaign), and 'pdays' (days from last contact). Now also 'balance' shows relevance, even higher than 'loan' (people with loans might not engage to the fix term deposit) and 'campaign' (number of contacts in this campaign)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f7977d1",
   "metadata": {},
   "source": [
    "##### Categorical variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63fda668",
   "metadata": {},
   "source": [
    "##### A. Mean difference and risk ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d2a28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in categorical:\n",
    "    print(c)\n",
    "    df_group = df.groupby(c).deposit.agg(['mean', 'count'])\n",
    "    df_group['diff'] = df_group['mean'] - df.deposit.mean() # mean difference\n",
    "    df_group['risk'] = df_group['mean'] / df.deposit.mean() # risk ratio\n",
    "    display(df_group)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e92e834",
   "metadata": {},
   "source": [
    "It seems that 'month' (specially 'December' and 'March' with a risk ratio about 90% above average), 'job' (specially 'retired' and 'student') and previous outcome 'poutcome' (specially 'success') significatively affect if there is a deposit or not. The 'unknown' value of the feature 'contact' also shows an effect on the target variable, although this might not be very informative (low decision power)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80fccc00",
   "metadata": {},
   "source": [
    "##### B. Mutual Information\n",
    "\n",
    "From [information theory](https://en.wikipedia.org/wiki/Mutual_information), for categorical variables, it tells us how much we can learn about one variable if we know the value of another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3237d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mut_inf_deposit_score(series):\n",
    "    return mutual_info_score(series, df.deposit)\n",
    "\n",
    "# apply the function column-wise\n",
    "MutInf = df[categorical].apply(mut_inf_deposit_score)\n",
    "MutInf.sort_values(ascending=False) # to sort it"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ed240c",
   "metadata": {},
   "source": [
    "##### Feature importance summary\n",
    "\n",
    "The next highest correlations in the numerical features are a positive correlation with **'pdays'** (days from last contact) and **'previous'** (contacts before this campaign) and negative correlations with **'housing'** and **'loan'** (people with loans might not engage to the fix term deposit) and **'campaign'** (number of contacts in this campaign).\n",
    "\n",
    "The previous outcome **'poutcome'**, **'contact'**, and **'job'**, seem to be the most relevant categorical features. \n",
    "\n",
    "We still use all of them (see the Model Selection section about the results if we dismiss 'duration', as suggested by the data provider) since 15 is a suitable number of features. So far, the 'unknown' values has not being converted to NaNs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9adf5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_select = df.copy() \n",
    "#del df_select['duration']  \n",
    "categorical = df_select.select_dtypes(include=['object']).columns.tolist()\n",
    "numerical = df_select.select_dtypes(include=['int64']).columns.tolist()\n",
    "numerical.remove('deposit')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d52bcf",
   "metadata": {},
   "source": [
    "Uncomment the removal of the feature 'duration' to check how is performance without this feature, which is defined as problematic by the dat aprovider, see above. When uncommented, the final XGBoost ROC AUC in the Model selection section is ~0.787."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdea30cf",
   "metadata": {},
   "source": [
    "### 2.5 Doing the train/val/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b473b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate train + validation (= full) and test\n",
    "df_full_train, df_test = train_test_split(df_select, test_size=0.2, random_state=1)\n",
    "# now split the full into train and val, it should be the 20% of the 80%, which is 20/80=1/4=0.25\n",
    "df_train, df_val = train_test_split(df_full_train, test_size=0.25, random_state=1) \n",
    "len(df_train), len(df_val), len(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f65631",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset index\n",
    "df_train = df_train.reset_index(drop=True)\n",
    "df_val = df_val.reset_index(drop=True)\n",
    "\n",
    "# separate the target\n",
    "y_train = df_train.deposit.values\n",
    "y_val = df_val.deposit.values\n",
    "\n",
    "# remove the target from the features\n",
    "del df_train['deposit']\n",
    "del df_val['deposit']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f40dc0a",
   "metadata": {},
   "source": [
    "### 2.6 Encoding the categorical variables\n",
    "\n",
    "We use Scikit-Learn DictVectorizer to encode categorical features (it takes a dictionary and convert it to a vector (numpy.array)). It is One-hot encoding (OHE) method to converts the categorical features in binary (it would not affect the numerical ones), in as much columns as values the categorical variable takes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c576a8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "dv = DictVectorizer(sparse=False) # False bcs is not a sparse matrix (we do not have many zeros)\n",
    "\n",
    "# TRAIN\n",
    "train_dict = df_train[categorical].to_dict(orient='records') # records = to do it row-wise, not col-wise\n",
    "X_train_cat = dv.fit_transform(train_dict) # make it a vector\n",
    "\n",
    "# VAL\n",
    "val_dict = df_val[categorical].to_dict(orient='records')\n",
    "X_val_cat = dv.transform(val_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b881f8c",
   "metadata": {},
   "source": [
    "### 2.7 Scaling the numerical variables\n",
    "\n",
    "We use Scikit-Learn StandardScaler to scale the numerical features (otherwise columns with values in a higher range would have more representation and the model does not converge)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a24322",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "# TRAIN\n",
    "X_train_num = df_train[numerical].values\n",
    "X_train_num = scaler.fit_transform(X_train_num)\n",
    "\n",
    "# VAL\n",
    "X_val_num = df_val[numerical].values\n",
    "X_val_num = scaler.transform(X_val_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57765afb",
   "metadata": {},
   "source": [
    "We join the numerical and categorical matrices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede9d280",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN\n",
    "X_train = np.column_stack([X_train_num, X_train_cat])\n",
    "\n",
    "# VAL\n",
    "X_val = np.column_stack([X_val_num, X_val_cat])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71998daf",
   "metadata": {},
   "source": [
    "## 3 Model training\n",
    "\n",
    "### 3.1 Metric selection\n",
    "\n",
    "As the target in the dataset is quite balanced, the performance metrics we will use are:\n",
    "+ [Accuracy](https://en.wikipedia.org/wiki/Accuracy_and_precision#In_binary_classification) i.e., the proportion of right predictions, and \n",
    "+ [ROC AUC](https://en.wikipedia.org/wiki/Receiver_operating_characteristic), as mentioned above, the probability that a randomly selected positive example (someone that will actually open a fix term deposit) has a higher score (higher probability to be predicted as positive or higher feature value if we want to use ROC AUC for feature important) than a randomly selected negative example (someone that will not open a fix term deposit)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83a3d458",
   "metadata": {},
   "source": [
    "### 3.2 Logistic Regression\n",
    "\n",
    "A linear regression as we studied in school that applies a 'sigmoid' filter to the predictions thus the results are binary values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334d5167",
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = LogisticRegression(C=1.0, random_state=42) \n",
    "# solver='lbfgs' is the default solver in newer version of sklearn\n",
    "# the smallest the C, the stronger the regularizations (oposite to alpha o r)\n",
    "\n",
    "LR.fit(X_train, y_train)\n",
    "y_pred = LR.predict_proba(X_val)[:, 1] # left col is neg deposit (0), right col is pos deposit (1)\n",
    "  \n",
    "thresholds = np.linspace(0, 1, 5)\n",
    "LR_scores = []\n",
    "print('thres', 'acc')\n",
    "\n",
    "for t in thresholds: # above threshold the probability becomes 1, below, is zero\n",
    "    acc = accuracy_score(y_val, y_pred >= t) # it compares the 0/1 in y_val with the False/True of y_pred>=t\n",
    "    print('%.2f %.3f' % (t, acc))\n",
    "    LR_scores.append(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80db57a9",
   "metadata": {},
   "source": [
    "Best threshold is t = 0.5. A dummy threshold, t=0, means that the model predicts that none of the clients make a fix term deposit, and it is correct 50% of the times since the data are quite balanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c9e3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 0.5\n",
    "\n",
    "# TRAIN\n",
    "y_pred = LR.predict_proba(X_train)[:, 1]\n",
    "acc = accuracy_score(y_train, y_pred >= t) \n",
    "auc = roc_auc_score(y_train, y_pred)\n",
    "print('For the training dataset:','ACC:', acc.round(3), 'ROC AUC:', auc.round(3))\n",
    "\n",
    "# VAL\n",
    "y_pred = LR.predict_proba(X_val)[:, 1]\n",
    "LR_acc = accuracy_score(y_val, y_pred >= t) \n",
    "LR_auc = roc_auc_score(y_val, y_pred)\n",
    "print('For the validation dataset:','ACC:', LR_acc.round(3), 'ROC AUC:', LR_auc.round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef8377b",
   "metadata": {},
   "source": [
    "The performances of the model on the training and validation datasets are similar, thus there is not so much overfitting. The scores are good. Instead of tuning the parameters of the logistic regresion, let us try to improve the performance with non linear models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c713c8e6",
   "metadata": {},
   "source": [
    "### 3.3 Decision Tree Classifier\n",
    "\n",
    "Decision trees learn if-then-else rules from data where finding the best split (true or false in the condition) means to select the least impure split. This algorithm can overfit, that's why we control it by limiting the max depth and the size of the group. Let us find the best threshold to calculate the accuracy (as we did for the Logistic Regression model), then we tune the tree parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a427240",
   "metadata": {},
   "outputs": [],
   "source": [
    "DT = DecisionTreeClassifier(max_depth = 6, random_state=1)\n",
    "DT.fit(X_train, y_train)\n",
    "\n",
    "y_pred = DT.predict_proba(X_val)[:, 1] # left col is neg deposit (0), right col is pos deposit (1)\n",
    "  \n",
    "thresholds = np.linspace(0, 1, 5)\n",
    "DT_scores =[]\n",
    "print('thres', 'acc')\n",
    "\n",
    "for t in thresholds: # above threshold the probability becomes 1, below, is zero\n",
    "    score = accuracy_score(y_val, y_pred >= t) # it compares the 0/1 in y_val with the False/True of y_pred>=t\n",
    "    print('%.2f %.3f' % (t, score))\n",
    "    DT_scores.append(score)\n",
    "    \n",
    "print('the ROC AUC is', roc_auc_score(y_val, y_pred).round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed82b0f",
   "metadata": {},
   "source": [
    "Threshold t=0.5 seems to be the optimal choice again, thus we will just use it from now on. Let us find the best parameters for the decison tree classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "605fc337",
   "metadata": {},
   "outputs": [],
   "source": [
    "DT_scores = []\n",
    "t = 0.5\n",
    "\n",
    "for depth in [4, 5, 6]:\n",
    "    for s in [1, 5, 10, 15, 20, 500, 100, 200]:\n",
    "        DT = DecisionTreeClassifier(max_depth=depth, min_samples_leaf=s, random_state = 1)\n",
    "        DT.fit(X_train, y_train)\n",
    "\n",
    "        y_pred = DT.predict_proba(X_val)[:, 1]\n",
    "        acc = accuracy_score(y_val, y_pred >= t) \n",
    "        auc = roc_auc_score(y_val, y_pred)\n",
    "        \n",
    "        DT_scores.append((depth, s, acc, auc))\n",
    "        \n",
    "columns = ['max_depth', 'min_samples_leaf', 'acc','auc']\n",
    "df_scores = pd.DataFrame(DT_scores, columns=columns)\n",
    "df_scores_pivot = df_scores.pivot(index='min_samples_leaf', columns=['max_depth'], values=['acc','auc'])\n",
    "sns.heatmap(df_scores_pivot, annot=True, fmt=\".3f\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6863006f",
   "metadata": {},
   "source": [
    "It seems that max_depth=6 and min_samples_leaf=5 are good enought (the performance on the training and the validation data should not be too apart or the model will overfit and not generalize well for the final test dataset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101fdea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 0.5\n",
    "DT = DecisionTreeClassifier(max_depth=6, min_samples_leaf=5, random_state =1)\n",
    "DT.fit(X_train, y_train)\n",
    "\n",
    "# TRAIN\n",
    "y_pred = DT.predict_proba(X_train)[:, 1]\n",
    "acc = accuracy_score(y_train, y_pred >= t) \n",
    "auc = roc_auc_score(y_train, y_pred)\n",
    "print('For the training dataset:','ACC:', acc.round(3), 'ROC AUC:', auc.round(3))\n",
    "\n",
    "# VAL\n",
    "y_pred = DT.predict_proba(X_val)[:, 1]\n",
    "DT_acc = accuracy_score(y_val, y_pred >= t) \n",
    "DT_auc = roc_auc_score(y_val, y_pred)\n",
    "print('For the validation dataset:','ACC:', DT_acc.round(3), 'ROC AUC:', DT_auc.round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b5439e",
   "metadata": {},
   "source": [
    "The performances on the training and validation datasets are similar, there is not overfitting. \n",
    "Let us see how the leafs and branches look like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bcefcaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(export_text(DT, feature_names=numerical + dv.get_feature_names()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b30d36df",
   "metadata": {},
   "source": [
    "Apart from **'duration'** (which according to the data provider could be problematic, see the notebook intro), it seems that the features with more decision power in the tree are:\n",
    "+ **'poutcome'**, i.e. if the previous campaign worked with this client or not, it also showed a high feature importance in the EDA section (although it can be not informative since there are many 'unknown' values),\n",
    "+ **'contact'**, i.e., how was the cliented contacted (although it can be not informative since there are many 'unknown' values), and \n",
    "+ **'campaign'**, i.e., how many times the client was contacted during the campaign, it showed some (negative) correlation with the target in the EDA, and there are not 'unknown' values, it seems to be an important tree branch with high prediction power in combination with 'pdays'. \n",
    "\n",
    "Surprisingly, **'housing'** showed higher correlation with 'deposit' and higher ROC AUC than 'campaign', but here it seems to be as relevant as **'month'** (some 'month' values showed a very high risk ratio in the EDA)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "941ac80b",
   "metadata": {},
   "source": [
    "### 3.4 Random Forest\n",
    "\n",
    "Let us go for ensemble learning and run in parallel many trees and take the average result. Random forest is a way of combininig multiple decision trees. It should have a diverse set of models to make good predictions (although here we will not explore the 'bootstrap' option). First we find the best parameters: first the max_depth, then the min_samples_leaf, and finally the n_estimators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a5cb98",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%timeit  # it takes about 1min\n",
    "if True:#False:\n",
    "    RF_scores = []\n",
    "    t =0.5\n",
    "\n",
    "    for d in [5, 10, 15]:\n",
    "        for n in range(10, 201, 10):\n",
    "            RF = RandomForestClassifier(n_estimators=n,\n",
    "                                        max_depth=d,\n",
    "                                        random_state=1)\n",
    "            RF.fit(X_train, y_train)\n",
    "\n",
    "            y_pred = RF.predict_proba(X_val)[:, 1]\n",
    "            acc = accuracy_score(y_val, y_pred >= t) \n",
    "            auc = roc_auc_score(y_val, y_pred)\n",
    "\n",
    "            RF_scores.append((d, n, acc, auc))\n",
    "\n",
    "    columns = ['max_depth', 'n_estimators', 'acc','auc']\n",
    "    df_scores = pd.DataFrame(RF_scores, columns=columns)\n",
    "    df_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87feda4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(15, 3))\n",
    "fig.tight_layout()\n",
    "\n",
    "for d in [5, 10, 15]:\n",
    "    df_subset = df_scores[df_scores.max_depth == d]\n",
    "    \n",
    "    axes[0].plot(df_subset.n_estimators, df_subset.acc,\n",
    "             label='max_depth=%d' % d)\n",
    "    axes[0].set_title('Accuracy')\n",
    "    axes[0].set_xlabel('no. of trees')\n",
    "\n",
    "    axes[1].plot(df_subset.n_estimators, df_subset.auc,\n",
    "             label='max_depth=%d' % d)\n",
    "    axes[1].set_title('ROC AUC')\n",
    "    axes[1].set_xlabel('no. of trees')\n",
    "\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58bffe90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%timeit it takes about 1min\n",
    "\n",
    "if True:#False:\n",
    "    max_depth = 15\n",
    "    t=0.5\n",
    "\n",
    "    RF_scores = []\n",
    "\n",
    "    for s in [1, 3, 5, 10, 50]:\n",
    "        for n in range(10, 201, 10):\n",
    "            RF = RandomForestClassifier(n_estimators=n,\n",
    "                                        max_depth=max_depth,\n",
    "                                        min_samples_leaf=s,\n",
    "                                        random_state=1)\n",
    "            RF.fit(X_train, y_train)\n",
    "\n",
    "            y_pred = RF.predict_proba(X_val)[:, 1]\n",
    "            acc = accuracy_score(y_val, y_pred >= t)         \n",
    "            auc = roc_auc_score(y_val, y_pred)\n",
    "\n",
    "            RF_scores.append((s, n, acc, auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85de06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['min_samples_leaf', 'n_estimators', 'acc','auc']\n",
    "df_scores = pd.DataFrame(RF_scores, columns=columns)\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(15, 3))\n",
    "fig.tight_layout()\n",
    "\n",
    "colors = ['black', 'blue', 'orange', 'red', 'grey']\n",
    "values = [1, 3, 5, 10, 50]\n",
    "\n",
    "for s, col in zip(values, colors):\n",
    "    df_subset = df_scores[df_scores.min_samples_leaf == s]\n",
    "    \n",
    "    axes[0].plot(df_subset.n_estimators, df_subset.acc,\n",
    "             color=col,\n",
    "             label='min_samples_leaf=%d' % s)\n",
    "    axes[0].set_title('Accuracy')\n",
    "    axes[0].set_xlabel('no. of trees')\n",
    "\n",
    "    axes[1].plot(df_subset.n_estimators, df_subset.auc,\n",
    "             color=col,\n",
    "             label='min_samples_leaf=%d' % s)\n",
    "    axes[1].set_title('ROC AUC')\n",
    "    axes[1].set_xlabel('no. of trees')\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b2bdc05",
   "metadata": {},
   "source": [
    "The best parameters are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71cb9b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = 150\n",
    "min_samples_leaf = 1\n",
    "max_depth = 15\n",
    "t=0.5\n",
    "\n",
    "RF = RandomForestClassifier(n_estimators=n_estimators,\n",
    "                            max_depth=max_depth,\n",
    "                            min_samples_leaf=min_samples_leaf,\n",
    "                            random_state=1)\n",
    "RF.fit(X_train, y_train)\n",
    "\n",
    "# TRAIN\n",
    "y_pred = RF.predict_proba(X_train)[:, 1]\n",
    "acc = accuracy_score(y_train, y_pred >= t) \n",
    "auc = roc_auc_score(y_train, y_pred)\n",
    "print('For the training dataset:','ACC:', acc.round(3), 'ROC AUC:', auc.round(3))\n",
    "\n",
    "# VAL\n",
    "y_pred = RF.predict_proba(X_val)[:, 1]\n",
    "RF_acc = accuracy_score(y_val, y_pred >= t) \n",
    "RF_auc = roc_auc_score(y_val, y_pred)\n",
    "print('For the validation dataset:','ACC:', RF_acc.round(3), 'ROC AUC:', RF_auc.round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f89a4e",
   "metadata": {},
   "source": [
    "The performance on the training dataset is better than on the validation dataset, the model seems to overfit the target variable. Let us reduce the value of some parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5acec1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = 125 #150\n",
    "min_samples_leaf = 10 #3\n",
    "max_depth = 10 #15\n",
    "t=0.5\n",
    "\n",
    "RF = RandomForestClassifier(n_estimators=n_estimators,\n",
    "                            max_depth=max_depth,\n",
    "                            min_samples_leaf=min_samples_leaf,\n",
    "                            random_state=1)\n",
    "RF.fit(X_train, y_train)\n",
    "\n",
    "# TRAIN\n",
    "y_pred = RF.predict_proba(X_train)[:, 1]\n",
    "acc = accuracy_score(y_train, y_pred >= t) \n",
    "auc = roc_auc_score(y_train, y_pred)\n",
    "print('For the training dataset:','ACC:', acc.round(3), 'ROC AUC:', auc.round(3))\n",
    "\n",
    "# VAL\n",
    "y_pred = RF.predict_proba(X_val)[:, 1]\n",
    "RF_acc = accuracy_score(y_val, y_pred >= t) \n",
    "RF_auc = roc_auc_score(y_val, y_pred)\n",
    "print('For the validation dataset:','ACC:', RF_acc.round(3), 'ROC AUC:', RF_auc.round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a01f10f2",
   "metadata": {},
   "source": [
    "Now the performance on the validation is similar than with the optimal parameters set, but it is closer to the performance on the training dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f0433ec",
   "metadata": {},
   "source": [
    "### 3.5 XGBoost\n",
    "\n",
    "Gradient boosting trains model sequentially: each model tries to fix errors of the previous model. XGBoost is an implementation of gradient boosting. Then, we will run an ensemble of trees but not in parallel, thus the next tree can learn from the previous tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b46a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = numerical + dv.get_feature_names()\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train, feature_names=features)\n",
    "dval = xgb.DMatrix(X_val, label=y_val, feature_names=features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554435be",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_params = {\n",
    "    'eta': 0.3, #default is 0.3\n",
    "    'max_depth': 6, # default is 6\n",
    "    'min_child_weight': 1, # default is 1\n",
    "    \n",
    "    'objective': 'binary:logistic',\n",
    "    'nthread': 8,\n",
    "    'eval_metric': 'auc', # otherwise it uses logloss\n",
    "    \n",
    "    'seed': 1,\n",
    "    'verbosity': 1,\n",
    "}\n",
    "\n",
    "model = xgb.train(xgb_params, dtrain, num_boost_round=10)\n",
    "\n",
    "# TRAIN\n",
    "y_pred = model.predict(dtrain)\n",
    "acc = accuracy_score(y_train, y_pred >= t) \n",
    "auc = roc_auc_score(y_train, y_pred)\n",
    "print('For the training dataset:','ACC:', acc.round(3), 'ROC AUC:', auc.round(3))\n",
    "\n",
    "# VAL\n",
    "y_pred = model.predict(dval)\n",
    "xgb_acc = accuracy_score(y_val, y_pred >= t) \n",
    "xgb_auc = roc_auc_score(y_val, y_pred)\n",
    "print('For the validation dataset:','ACC:', xgb_acc.round(3), 'ROC AUC:', xgb_auc.round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ba3b41",
   "metadata": {},
   "source": [
    "Let us define the parameter ranges to find the best parameter values, first 'eta', then 'max_depth' and then\n",
    "'min_child_weight'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "620c815b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# performance monitoring: \n",
    "# after each round (i.e., after each new tree is trained) we inmediatly evaluate on the val dataset \n",
    "watchlist = [(dtrain, 'train'), (dval, 'val')]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ba31d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the XGB\n",
    "model = xgb.train(xgb_params, dtrain, num_boost_round=100,\n",
    "                verbose_eval=5, # we print the evaluation every 5 trees/iterations\n",
    "                evals=watchlist)\n",
    "# apply to val\n",
    "y_pred = model.predict(dval)\n",
    "# from the results in each round we can identify overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efcbe9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_params = {\n",
    "    'eta': 0.1, #default is 0.3\n",
    "    'max_depth': 6, # default is 6\n",
    "    'min_child_weight': 1, # default is 1\n",
    "    \n",
    "    'objective': 'binary:logistic',\n",
    "    'nthread': 8,\n",
    "    'eval_metric': 'auc', # otherwise it uses logloss\n",
    "    \n",
    "    'seed': 1,\n",
    "    'verbosity': 1,\n",
    "}\n",
    "# train the XGB\n",
    "model = xgb.train(xgb_params, dtrain, num_boost_round=100,\n",
    "                verbose_eval=5, # we print the evaluation every 5 trees/iterations\n",
    "                evals=watchlist)\n",
    "# apply to val\n",
    "y_pred = model.predict(dval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e4966f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_params = {\n",
    "    'eta': 0.01, #default is 0.3\n",
    "    'max_depth': 6, # default is 6\n",
    "    'min_child_weight': 1, # default is 1\n",
    "    \n",
    "    'objective': 'binary:logistic',\n",
    "    'nthread': 8,\n",
    "    'eval_metric': 'auc', # otherwise it uses logloss\n",
    "    \n",
    "    'seed': 1,\n",
    "    'verbosity': 1,\n",
    "}\n",
    "# train the XGB\n",
    "model = xgb.train(xgb_params, dtrain, num_boost_round=100,\n",
    "                verbose_eval=5, # we print the evaluation every 5 trees/iterations\n",
    "                evals=watchlist)\n",
    "# apply to val\n",
    "y_pred = model.predict(dval)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9721d7b1",
   "metadata": {},
   "source": [
    "With learnin grate 'eta = 0.1' in the round [50] we get 'train-auc:0.85489' and 'val-auc:0.77817', meaning that there is not so much overfitting and it is a reasonable good score. Let us tune the 'max_depth':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d43acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_params = {\n",
    "    'eta': 0.3, #default is 0.3\n",
    "    'max_depth': 4, # default is 6\n",
    "    'min_child_weight': 1, # default is 1\n",
    "    \n",
    "    'objective': 'binary:logistic',\n",
    "    'nthread': 8,\n",
    "    'eval_metric': 'auc', # otherwise it uses logloss\n",
    "    \n",
    "    'seed': 1,\n",
    "    'verbosity': 1,\n",
    "}\n",
    "# train the XGB\n",
    "model = xgb.train(xgb_params, dtrain, num_boost_round=100,\n",
    "                verbose_eval=5, # we print the evaluation every 5 trees/iterations\n",
    "                evals=watchlist)\n",
    "# apply to val\n",
    "y_pred = model.predict(dval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d348217",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_params = {\n",
    "    'eta': 0.3, #default is 0.3\n",
    "    'max_depth': 3, # default is 6\n",
    "    'min_child_weight': 1, # default is 1\n",
    "    \n",
    "    'objective': 'binary:logistic',\n",
    "    'nthread': 8,\n",
    "    'eval_metric': 'auc', # otherwise it uses logloss\n",
    "    \n",
    "    'seed': 1,\n",
    "    'verbosity': 1,\n",
    "}\n",
    "# train the XGB\n",
    "model = xgb.train(xgb_params, dtrain, num_boost_round=100,\n",
    "                verbose_eval=5, # we print the evaluation every 5 trees/iterations\n",
    "                evals=watchlist)\n",
    "# apply to val\n",
    "y_pred = model.predict(dval)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe189740",
   "metadata": {},
   "source": [
    "The best result with 'eta = 0.3' when varying 'max_depth' and avoiding overfitting seems to be 'max_depth=4' that in the round 25 gives 'train-auc: 0.9446' and 'val-auc: 0.9142'. Now we vary 'min_child_weight':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b5a70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_params = {\n",
    "    'eta': 0.3, #default is 0.3\n",
    "    'max_depth': 4, # default is 6\n",
    "    'min_child_weight': 10, # default is 1\n",
    "    \n",
    "    'objective': 'binary:logistic',\n",
    "    'nthread': 8,\n",
    "    'eval_metric': 'auc', # otherwise it uses logloss\n",
    "    \n",
    "    'seed': 1,\n",
    "    'verbosity': 1,\n",
    "}\n",
    "# train the XGB\n",
    "model = xgb.train(xgb_params, dtrain, num_boost_round=100,\n",
    "                verbose_eval=5, # we print the evaluation every 5 trees/iterations\n",
    "                evals=watchlist)\n",
    "# apply to val\n",
    "y_pred = model.predict(dval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e960d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_params = {\n",
    "    'eta': 0.3, #default is 0.3\n",
    "    'max_depth': 4, # default is 6\n",
    "    'min_child_weight': 30, # default is 1\n",
    "    \n",
    "    'objective': 'binary:logistic',\n",
    "    'nthread': 8,\n",
    "    'eval_metric': 'auc', # otherwise it uses logloss\n",
    "    \n",
    "    'seed': 1,\n",
    "    'verbosity': 1,\n",
    "}\n",
    "# train the XGB\n",
    "model = xgb.train(xgb_params, dtrain, num_boost_round=100,\n",
    "                verbose_eval=5, # we print the evaluation every 5 trees/iterations\n",
    "                evals=watchlist)\n",
    "# apply to val\n",
    "y_pred = model.predict(dval)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "862519c6",
   "metadata": {},
   "source": [
    "The default value 'min_child_weight = 1' gave the best results, in 25 rounds, both performances were high and similar: train-auc:0.94462 and val-auc:0.91423. Then, we select the following parameter set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437ba6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_params = {\n",
    "    'eta': 0.3, #default is 0.3\n",
    "    'max_depth': 4, # default is 6\n",
    "    'min_child_weight': 1, # default is 1\n",
    "    \n",
    "    'objective': 'binary:logistic',\n",
    "    'nthread': 8,\n",
    "    'eval_metric': 'auc', # otherwise it uses logloss\n",
    "    \n",
    "    'seed': 1,\n",
    "    'verbosity': 1,\n",
    "}\n",
    "model = xgb.train(xgb_params, dtrain, num_boost_round=25)\n",
    "y_pred = model.predict(dval)\n",
    "xgb_auc =roc_auc_score(y_val, y_pred)\n",
    "xgb_auc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ebfb7e",
   "metadata": {},
   "source": [
    "We can analyze the feature importances very clearly by using the plot_importance() method. This gives the relative importance of all the features in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022b6c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.rcParams['figure.dpi'] = 120 \n",
    "plt.rcParams.update({'font.size': 8})\n",
    "xgb.plot_importance(model)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e03108",
   "metadata": {},
   "source": [
    "Interestingly, with the F-score as metric, the features 'age' and 'balance' become very relevant, which makes a lot of sense. Besides, we show in the previous analysis, that 'duration' is significatively important, as 'pdays' and a success in the previous campaign or 'poutcome=success'."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb8f896",
   "metadata": {},
   "source": [
    "### 3.6 Model selection \n",
    "\n",
    "We will choose and train the final model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c15c468",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Model performance ROC AUC on the validation dataset:')\n",
    "print()\n",
    "print('XGBoost', xgb_auc.round(3))\n",
    "print('Random Forest', RF_auc.round(3))\n",
    "print('Logistic Regresssion:', LR_auc.round(3))\n",
    "print('Decission Tree Classifier:', DT_auc.round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75292162",
   "metadata": {},
   "source": [
    "When we removed the feature 'duration' following the data provider recommendation (see the data descripcion above), we obtained the following ROC AUC on the validation dataset (the code is not shown here, to reproduce the results, uncomment the line where we deleted the 'duration' feature just before splitting):\n",
    "+ XGBoost 0.781 ('eta': 0.1, 'max_depth': 4, 'min_child_weight': 1, and 70 rounds)\n",
    "+ Random Forest 0.779 (same parameters than here)\n",
    "+ Logistic Regresssion: 0.749\n",
    "+ Decission Tree Classifier: 0.725 (same parameters than here).\n",
    "\n",
    "**The best performer is XGBboost in both cases.** We continue with the analysis that includes all the features.\n",
    "\n",
    "We train it on the 'full_train' dataset and test it on the test dataset with a k-fold cross validation. Let us prepare the full_train and test datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf78a36c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN\n",
    "df_full_train = df_full_train.reset_index(drop=True) # reset index after splitting shuffling\n",
    "y_full_train = df_full_train.deposit.values\n",
    "\n",
    "#del df_full_train['deposit'] # remove target\n",
    "    \n",
    "full_train_dict = df_full_train[categorical].to_dict(orient='records')\n",
    "X_full_train_cat = dv.fit_transform(full_train_dict) # encode the categorical features\n",
    "\n",
    "X_full_train_num = df_full_train[numerical].values\n",
    "X_full_train_num = scaler.fit_transform(X_full_train_num) # scale the numerical features\n",
    "\n",
    "X_full_train = np.column_stack([X_full_train_num, X_full_train_cat]) # join the matrices\n",
    "\n",
    "# TEST\n",
    "df_test = df_test.reset_index(drop=True) # reset index after splitting shuffling\n",
    "y_test = df_test.deposit.values\n",
    "\n",
    "del df_test['deposit'] # remove target\n",
    "    \n",
    "test_dict = df_test[categorical].to_dict(orient='records')\n",
    "X_test_cat = dv.transform(test_dict) # encode the categorical features\n",
    "\n",
    "X_test_num = df_test[numerical].values\n",
    "X_test_num = scaler.transform(X_test_num) # scale the numerical features\n",
    "\n",
    "X_test = np.column_stack([X_test_num, X_test_cat]) # join the matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab390280",
   "metadata": {},
   "source": [
    "Create the DMatrices for XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22fff5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfulltrain = xgb.DMatrix(X_full_train, label=y_full_train,\n",
    "                    feature_names=numerical + dv.get_feature_names())\n",
    "\n",
    "dtest = xgb.DMatrix(X_test, feature_names=numerical + dv.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def97daa",
   "metadata": {},
   "source": [
    "Train and apply the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0576d8a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_params = {\n",
    "    'eta': 0.3, #default is 0.3\n",
    "    'max_depth': 4, # default is 6\n",
    "    'min_child_weight': 1, # default is 1\n",
    "    \n",
    "    'objective': 'binary:logistic',\n",
    "    'nthread': 8,\n",
    "    'eval_metric': 'auc', # otherwise it uses logloss\n",
    "    \n",
    "    'seed': 1,\n",
    "    'verbosity': 1,\n",
    "}\n",
    "model = xgb.train(xgb_params, dfulltrain, num_boost_round=25)\n",
    "y_pred = model.predict(dtest)\n",
    "xgb_auc =roc_auc_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730f9795",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_auc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "194ebc50",
   "metadata": {},
   "source": [
    "The performance on the test dataset is good and similar to the previous performances on the training and validation datasets. Let us see if it is robust with a k-fold cross-validation: we evaluate the same model on different subsets of data (k-subsets, called fold) and we get the average prediction and the spread of the predictions. It is a powerful preventative measure against overfitting thus the model might be capable of generalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1544620b",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_fold = 5\n",
    "dfulltrain = xgb.DMatrix(X_full_train, label=y_full_train, feature_names=features)\n",
    "cv_results = xgb.cv(dtrain=dfulltrain, params=xgb_params, nfold=n_fold, num_boost_round=25,as_pandas=True,seed =1)\n",
    "cv_results.iloc[-1] # results of the last xgb round"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae36d301",
   "metadata": {},
   "source": [
    "The final model is quite stable. Let us save it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "605a71e0",
   "metadata": {},
   "source": [
    "## 4. Exporting to notebook to a python script\n",
    "\n",
    "The logic for training the model is exported to a separate script:\n",
    "+ in 'File', 'Download as', 'as Python (.py)' \n",
    "\n",
    "and then we save the trained model in the computer with pickle.\n",
    "\n",
    "See the README.md of the [Github repo](https://github.com/MMdeCastro/ml-zoomcamp/tree/main/Midterm_project) for the next steps:\n",
    "+ Model deployment with Flask\n",
    "+ Dependency and enviroment management with pipenv*\n",
    "+ Containerization with Docker\n",
    "+ Cloud deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f560dff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
