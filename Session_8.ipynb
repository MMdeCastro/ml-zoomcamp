{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "497cdd62",
   "metadata": {},
   "source": [
    "# Convolutional Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "086aabd4",
   "metadata": {},
   "source": [
    "+ image 150x150\n",
    "+ 32 filters of size 3x3 (so it filters 3 pixels x 3 pixels)\n",
    "+ the filter is moved around the image in strides, default is stride = (1,1) pixels\n",
    "+ MaxPool2 pooling layers takes 2x2 windows of the feature map and take the maximum of it\n",
    "+ Flatten layer: takes a chunk of whaterver dimension and makes a 1D vect "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "481bd873",
   "metadata": {},
   "source": [
    "## 1. Data Preparation\n",
    "\n",
    "Download the [cats and dogs dataset](https://www.kaggle.com/c/dogs-vs-cats/data) from Kaggle or from here:\n",
    "\n",
    "!wget https://github.com/alexeygrigorev/large-datasets/releases/download/dogs-cats/train.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2dd0c008",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "from tensorflow.keras.layers import Conv2D, Dense, MaxPool2D, Flatten, Dropout\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "#from tensorflow.keras.preprocessing.image import load_img\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02eb37ec",
   "metadata": {},
   "source": [
    "Create a train and validation folders. In each folder, create cats and dogs folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4d505d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if False: # this and the next 2 cells should be run only once, set 'False' to 'True'\n",
    "    train_dir = './cats_dogs/train'\n",
    "    val_dir = './cats_dogs/val'\n",
    "\n",
    "    dog_train_dir = './cats_dogs/train/dog'\n",
    "    dog_val_dir = './cats_dogs/val/dog'\n",
    "    cat_train_dir = './cats_dogs/train/cat'\n",
    "    cat_val_dir = './cats_dogs/val/cat'\n",
    "\n",
    "    file_dirs = [train_dir, val_dir, dog_train_dir, dog_val_dir, cat_train_dir, cat_val_dir]\n",
    "\n",
    "    for dir in file_dirs:\n",
    "        os.makedirs(dir,exist_ok = True)\n",
    "    \n",
    "    print(len(os.listdir(train_dir)))\n",
    "    print(len(os.listdir(val_dir)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda0ea39",
   "metadata": {},
   "source": [
    "Move the first 10,000 images to the train folder (from 0 to 9999) for boths cats and dogs - and put them in respective folders. Move the remaining 2,500 images to the validation folder (from 10000 to 12499)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45e54342",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move the first 10,000 images to the train folder (from 0 to 9999) for boths cats and dogs in respective folders\n",
    "if False:\n",
    "    source_folder = './cats_dogs/train/'\n",
    "    destination_folder = './cats_dogs/train/'\n",
    "\n",
    "    # iterate files\n",
    "    for spc in ['dog','cat']:\n",
    "        for num in range(0,10000):\n",
    "            # construct full file path\n",
    "            source = source_folder + '{}.{}.jpg'.format(spc,num)\n",
    "            destination = destination_folder + '{}/'.format(spc) + '{}.{}.jpg'.format(spc,num)\n",
    "            # move file\n",
    "            shutil.move(source, destination)\n",
    "            # print('Moved:', '{}.{}.jpg'.format(spc,num)) \n",
    "    print(len(os.listdir(train_dir)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a073fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move the remaining 2500 images to the val folder (from 10000 to 12499) for boths cats and dogs\n",
    "if False:\n",
    "    source_folder = './cats_dogs/train/'\n",
    "    destination_folder = './cats_dogs/val/'\n",
    "\n",
    "    # iterate files\n",
    "    for spc in ['dog','cat']:\n",
    "        for num in range(10000,12500):\n",
    "            # construct full file path\n",
    "            source = source_folder + '{}.{}.jpg'.format(spc,num)\n",
    "            destination = destination_folder + '{}/'.format(spc) + '{}.{}.jpg'.format(spc,num)\n",
    "            # move file\n",
    "            shutil.move(source, destination)\n",
    "            print('Moved:', '{}.{}.jpg'.format(spc,num))\n",
    "    \n",
    "    print(len(os.listdir(train_dir)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3153b702",
   "metadata": {},
   "source": [
    "## 2. Model\n",
    "\n",
    "We use a Convolutional Neural Network (CNN) in Keras. This is the model structure:\n",
    "\n",
    "\n",
    "* The shape for input should be `(150, 150, 3)`\n",
    "* Create a convolutional layer ([`Conv2D`](https://keras.io/api/layers/convolution_layers/convolution2d/)):\n",
    "    * Use 32 filters\n",
    "    * Kernel size should be `(3, 3)` (that's the size of the filter)\n",
    "    * Use `'relu'` as activation \n",
    "* Reduce the size of the feature map with max pooling ([`MaxPooling2D`](https://keras.io/api/layers/pooling_layers/max_pooling2d/))\n",
    "    * Set the pooling size to `(2, 2)`\n",
    "* Turn the multi-dimensional result into vectors using a [`Flatten`](https://keras.io/api/layers/reshaping_layers/flatten/) layer\n",
    "* Add a `Dense` layer with 64 neurons and `'relu'` activation\n",
    "* Create the `Dense` layer with 1 neuron - this will be the output\n",
    "    * The output layer should have an activation - sigmoid is the appropiate for the binary classification case ([Ref](https://ecwuuuuu.com/post/sigmoid-softmax-binary-class/))\n",
    "            \n",
    "We can transform the sigmoid function into softmax form. So sigmoid activation can consider as a special case of softmax activation with one of the two nodes have no weight given to it (just one node is working). \n",
    "From the architectural point of view, they are clearly different. Although there is no empirical result to show which one is better. It is clear to show that if the softmax way is chosen, the model will have more parameters that need to learn. So I think that is why people usually use one output neuron and the sigmoid activation function for binary classification.\n",
    "\n",
    "\n",
    "As optimizer use [`SGD`](https://keras.io/api/optimizers/sgd/) with the following parameters:\n",
    "\n",
    "* `SGD(lr=0.002, momentum=0.8)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd62015f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(input_size=150, learning_rate=0.01, size_inner=64):#,droprate=0.5):\n",
    "\n",
    "    #########################################\n",
    "\n",
    "    inputs = keras.Input(shape=(input_size, input_size, 3))\n",
    "    conv = keras.layers.Conv2D(32, (3,3), activation='relu',input_shape=(input_size, input_size, 3))(inputs)\n",
    "    \n",
    "    tensors = keras.layers.MaxPooling2D(pool_size=(2, 2))(conv)\n",
    "    vectors = keras.layers.Flatten()(tensors)\n",
    "    \n",
    "    inner = keras.layers.Dense(size_inner, activation='relu')(vectors)\n",
    "    # drop = keras.layers.Dropout(droprate)(inner)\n",
    "    \n",
    "    outputs = keras.layers.Dense(1, activation='sigmoid')(inner) #(drop)\n",
    "    \n",
    "    model = keras.Model(inputs, outputs)\n",
    "    \n",
    "    #########################################\n",
    "\n",
    "    optimizer = keras.optimizers.SGD(lr=0.002, momentum=0.8)\n",
    "    loss = keras.losses.BinaryCrossentropy(from_logits=False) # activation in output layer, no need from_logits=True\n",
    "\n",
    "    model.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "afcf166c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-22 14:08:02.913715: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2021-11-22 14:08:02.913758: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2021-11-22 14:08:02.913796: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (granada): /proc/driver/nvidia/version does not exist\n",
      "2021-11-22 14:08:02.914960: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-11-22 14:08:02.943614: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 44859392 exceeds 10% of free system memory.\n",
      "2021-11-22 14:08:03.007217: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 44859392 exceeds 10% of free system memory.\n",
      "2021-11-22 14:08:03.070504: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 44859392 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 150, 150, 3)]     0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 148, 148, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 74, 74, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 175232)            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                11214912  \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 11,215,873\n",
      "Trainable params: 11,215,873\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mmc/miniconda3/envs/ml-zoomcamp/lib/python3.8/site-packages/keras/optimizer_v2/optimizer_v2.py:355: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "make_model().summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a723807",
   "metadata": {},
   "source": [
    "Since we have a binary classification problem, we used BinaryCrossentropy as loss function.\n",
    "\n",
    "The model has 11,215,873 parameters.\n",
    "\n",
    "### Generators and Training\n",
    "\n",
    "We use the following data generator for both train and validation:\n",
    "\n",
    "```python\n",
    "ImageDataGenerator(rescale=1./255)\n",
    "```\n",
    "* We don't need to do any additional pre-processing for the images.\n",
    "* we use `class_mode = binary`, `batch_size=20` and `shuffle=True` for both training and validaition "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ad2bb93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20000 images belonging to 2 classes.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'cat': 0, 'dog': 1}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TRAIN\n",
    "train_dir = './cats_dogs/train' # in case the corresponding cell above is set False\n",
    "train_gen = ImageDataGenerator(rescale=1./255)\n",
    "train_ds = train_gen.flow_from_directory(\n",
    "    train_dir,\n",
    "    batch_size=20,\n",
    "    class_mode='binary',\n",
    "    target_size=(150, 150),\n",
    "    shuffle=True\n",
    ")\n",
    "train_ds.class_indices # OHE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c67390cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5000 images belonging to 2 classes.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'cat': 0, 'dog': 1}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# VAL\n",
    "val_dir = './cats_dogs/val' # in case the corresponding cell above is set False\n",
    "val_gen = ImageDataGenerator(rescale=1./255)\n",
    "val_ds = val_gen.flow_from_directory(\n",
    "    val_dir,\n",
    "    batch_size = 10,\n",
    "    class_mode = 'binary',\n",
    "    target_size=(150, 150),\n",
    "    shuffle=True\n",
    ")\n",
    "val_ds.class_indices # OHE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c789cc5e",
   "metadata": {},
   "source": [
    "We train with `.fit()` with the following params:\n",
    "\n",
    "```python\n",
    "model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=100,\n",
    "    epochs=10,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=50\n",
    ")\n",
    "```\n",
    "\n",
    "Note `validation_steps=50` - this parameter says \"run only 50 steps on the validation data for evaluating the results\". \n",
    "This way we iterate a bit faster, but don't use the entire validation dataset.\n",
    "That's why it's important to shuffle the validation dataset as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8a0bbfaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-22 14:08:04.198953: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 44859392 exceeds 10% of free system memory.\n",
      "2021-11-22 14:08:04.250957: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 44859392 exceeds 10% of free system memory.\n",
      "2021-11-22 14:08:04.921425: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "100/100 [==============================] - 32s 308ms/step - loss: 0.6973 - accuracy: 0.4975 - val_loss: 0.6908 - val_accuracy: 0.5380\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 31s 306ms/step - loss: 0.6887 - accuracy: 0.5390 - val_loss: 0.6818 - val_accuracy: 0.5920\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 31s 310ms/step - loss: 0.6857 - accuracy: 0.5510 - val_loss: 0.6827 - val_accuracy: 0.5540\n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 31s 305ms/step - loss: 0.6827 - accuracy: 0.5595 - val_loss: 0.6793 - val_accuracy: 0.5580\n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 31s 305ms/step - loss: 0.6780 - accuracy: 0.5645 - val_loss: 0.6774 - val_accuracy: 0.5680\n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 31s 310ms/step - loss: 0.6753 - accuracy: 0.5650 - val_loss: 0.6661 - val_accuracy: 0.5760\n",
      "Epoch 7/10\n",
      "100/100 [==============================] - 31s 311ms/step - loss: 0.6740 - accuracy: 0.5780 - val_loss: 0.6628 - val_accuracy: 0.5960\n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 31s 305ms/step - loss: 0.6613 - accuracy: 0.6090 - val_loss: 0.6581 - val_accuracy: 0.6180\n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 31s 306ms/step - loss: 0.6559 - accuracy: 0.6050 - val_loss: 0.6559 - val_accuracy: 0.5720\n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 31s 311ms/step - loss: 0.6579 - accuracy: 0.6175 - val_loss: 0.6653 - val_accuracy: 0.5800\n"
     ]
    }
   ],
   "source": [
    "# Fit data to model  (10 epochs took about 6min)\n",
    "model = make_model()\n",
    "history = model.fit(\n",
    "            train_ds,\n",
    "            steps_per_epoch=100,\n",
    "            epochs=10,\n",
    "            validation_data=val_ds,\n",
    "            validation_steps=50\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e62ecd",
   "metadata": {},
   "source": [
    "The median of training accuracy for this model is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "669399f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.56"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.median(history.history['accuracy']).round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef694e9c",
   "metadata": {},
   "source": [
    "The standard deviation of training loss for this model is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "29f547da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(history.history['loss']).round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "806edcf5",
   "metadata": {},
   "source": [
    "### Data Augmentation\n",
    "\n",
    "We'll now generate more data using data augmentations. \n",
    "\n",
    "We add the following augmentations to the training data generator:\n",
    "\n",
    "* `rotation_range=40,`\n",
    "* `width_shift_range=0.2,`\n",
    "* `height_shift_range=0.2,`\n",
    "* `shear_range=0.2,`\n",
    "* `zoom_range=0.2,`\n",
    "* `horizontal_flip=True,`\n",
    "* `fill_mode='nearest'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "90aa7992",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# TRAIN\n",
    "train_dir = './cats_dogs/train' # in case the corresponding cell above is set False\n",
    "train_gen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=40, # takes the range [-30, 30] and rotates each image randomly in that range\n",
    "    width_shift_range=0.2, # shift the image on a specific axis in the range [-10, 10].\n",
    "    height_shift_range=0.2, # shift the image on a specific axis in the range [-10, 10].\n",
    "    shear_range=0.2, # distort the image on a specific axis in the range [-10, 10])\n",
    "    zoom_range=0.2, # ndicates the amount of change, so 0.1 means the range will be [0.9, 1.1].\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "train_ds = train_gen.flow_from_directory(\n",
    "    train_dir,\n",
    "    batch_size=20,\n",
    "    class_mode='binary',\n",
    "    target_size=(150, 150),\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc3d62b",
   "metadata": {},
   "source": [
    "Let's train our model for 10 more epochs using the same code as previously. We don't re-create the model - we want to continue training the model we already started training. We don't need to recompile it. But even if you compile again, it doesn't reset the model you trained previously (re-running the cell where we defined the model will change it, tough)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9b17b9e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "100/100 [==============================] - 37s 366ms/step - loss: 0.6964 - accuracy: 0.5120 - val_loss: 0.6991 - val_accuracy: 0.4580\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 37s 365ms/step - loss: 0.6905 - accuracy: 0.5325 - val_loss: 0.6913 - val_accuracy: 0.5180\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 37s 367ms/step - loss: 0.6864 - accuracy: 0.5405 - val_loss: 0.6803 - val_accuracy: 0.5960\n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 39s 390ms/step - loss: 0.6845 - accuracy: 0.5630 - val_loss: 0.6849 - val_accuracy: 0.5560\n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 37s 374ms/step - loss: 0.6850 - accuracy: 0.5515 - val_loss: 0.6899 - val_accuracy: 0.5180\n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 37s 371ms/step - loss: 0.6851 - accuracy: 0.5365 - val_loss: 0.6815 - val_accuracy: 0.5620\n",
      "Epoch 7/10\n",
      "100/100 [==============================] - 38s 376ms/step - loss: 0.6826 - accuracy: 0.5575 - val_loss: 0.6781 - val_accuracy: 0.5680\n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 37s 374ms/step - loss: 0.6844 - accuracy: 0.5585 - val_loss: 0.6740 - val_accuracy: 0.5660\n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 37s 369ms/step - loss: 0.6796 - accuracy: 0.5680 - val_loss: 0.6688 - val_accuracy: 0.6120\n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 38s 376ms/step - loss: 0.6785 - accuracy: 0.5705 - val_loss: 0.6784 - val_accuracy: 0.5420\n"
     ]
    }
   ],
   "source": [
    "# Fit data to model  (10 epochs took about 6min) \n",
    "model = make_model()\n",
    "history = model.fit(\n",
    "            train_ds,\n",
    "            steps_per_epoch=100,\n",
    "            epochs=10,\n",
    "            validation_data=val_ds,\n",
    "            validation_steps=50\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5980c2ea",
   "metadata": {},
   "source": [
    "The mean of validation loss for the model trained with augmentations is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "39a80370",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.68"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(history.history['val_loss']).round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec7b5d9",
   "metadata": {},
   "source": [
    "The average of validation accuracy for the last 5 epochs (from 6 to 10) for the model trained with augmentations is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1d7b9e97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.572"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.average(history.history['val_accuracy'][6:10]).round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b8080bec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.57"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.average(history.history['val_accuracy'][5:10]).round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1baabdc8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
